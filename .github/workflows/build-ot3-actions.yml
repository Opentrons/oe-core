name: 'Build OT3 image on github workflows'

on:
  push:
    branches:
      - '*'
    tags-ignore:
      - '*'
  workflow_dispatch:

jobs:
  run-build:
    strategy:
      matrix:
        build_env: ['stage-prod']
    name: 'Building images on ${{ matrix.build_env }}'
    timeout-minutes: 480
    runs-on: ['self-hosted', '${{matrix.build_env}}']
    steps:
      - name: Fetch sources
        uses: 'actions/checkout@v3'
        with:
          submodules: false
          fetch-depth: 0
      - name: Sync oe-core submodules
        run: |
          chown -R `whoami` .
          whoami
          ls -la .
          ./update.sh
      - name: Configure AWS Credentials
        uses: './.github/actions/aws-credentials'
        id: aws
        with:
          access_key_id: ${{ secrets.ROBOT_STACK_AWS_ACCESS_KEY_ID }}
          secret_access_key: ${{ secrets.ROBOT_STACK_AWS_SECRET_ACCESS_KEY }}
          region: us-east-2
          stage: ${{ matrix.build_env }}
      - name: Build container
        run: |
          tmp_dir=$(mktemp -d -t ci-XXXXXXX)
          cp start.sh $tmp_dir/
          docker build -f ./Dockerfile --tag "ot3-image:latest" $tmp_dir
      - name: Apply CI config overrides
        run: |
          echo "" >> ./build/conf/local.conf
          echo 'DL_DIR = "/volumes/cache/downloads"' >> ./build/conf/local.conf
          echo 'GITDIR = "/volumes/cache/git"' >> ./build/conf/local.conf
          echo 'SSTATE_DIR = "/volumes/cache/sstate"' >> ./build/conf/local.conf
      - name: Pull S3 cache
        shell: bash
        run: |
          aws_cp="aws --profile=${{ steps.aws.outputs.profile_name }} s3 cp"
          cachedir=${LOCAL_CACHE:-./cache}
          for cachetype in downloads sstate git ; do
              localzip=${cachedir}/${cachetype}.zip
              thiscache=${cachedir}/${cachetype}
              echo "Fetching cache for ${cachetype}"
              mkdir -p ${thiscache}
              $aws_cp s3://${S3_CACHE_ARN/arn:aws:s3:::/}/${cachetype}.zip ${localzip} || continue
              unzip -u -o ${localzip} -d ${thiscache}
              df -h
          done
      - name: Download sources
        run: |
          docker run --rm --mount type=bind,src=$(pwd),dst=/volumes/oe-core,consistency=delegated --mount type=bind,src=${LOCAL_CACHE:-./cache},dst=/volumes/cache,consistency=delegated ot3-image:latest opentrons-ot3-image --runall=fetch
      - name: Build image
        run: |
          docker run --rm --mount type=bind,src=$(pwd),dst=/volumes/oe-core,consistency=delegated --mount type=bind,src=${LOCAL_CACHE:-./cache},dst=/volumes/cache,consistency=delegated ot3-image:latest
      - name: Prune images
        if: always()
        run: docker image prune -af
      - name: Remove poisoned cache
        if: ${{ !success() }}
        run: |
          rm -rf ${LOCAL_CACHE:-./cache}/*
      - name: Push S3 cache
        shell: bash
        run: |
          aws_cp="aws --profile=${{ steps.aws.outputs.profile_name }} s3 cp"
          cachedir=${LOCAL_CACHE:-./cache}
          for cachetype in downloads sstate git ; do
              localzip=${cachedir}/${cachetype}.zip
              thiscache=${cachedir}/${cachetype}
              cd ${thiscache}
              echo "Refreshing cache for ${cachetype}"
              zip -r --filesync --symlinks  ${localzip} ./*
              ${aws_cp} ${localzip} s3://${S3_CACHE_ARN/arn:aws:s3:::/}/${cachetype}.zip
          done
      - name: Gather results
        run: |
          mkdir -p build/deploy/opentrons
          find ./build/deploy/images -name "*opentrons-ot3-image-Tezi*" -exec cp {} build/deploy/opentrons/ot3-fullimage.tar \;
          find ./build/deploy/images -name "ot3-system.zip" -exec cp {} build/deploy/opentrons \;
          find ./build/deploy/images -name "VERSION.json" -exec cp {} build/deploy/opentrons \;
          tar czf ./build/deploy/opentrons/buildstats.tar.gz ./build/tmp/buildstats
      - name: Upload results to S3
        shell: bash
        id: 'upload-results'
        run: |
          cd build/deploy/
          aws --profile=${{ steps.aws.outputs.profile_name }} s3 cp --acl=public-read --recursive opentrons s3://${S3_ARTIFACT_ARN/arn:aws:s3:::/}/ot3-oe/${{ github.run_id }}
          root_url=https://${S3_ARTIFACT_ARN/arn:aws:s3:::/}/ot3-oe/${{ github.run_id }}
          echo "console_url=https://s3.console.aws.amazon.com/s3/buckets/${S3_ARTIFACT_ARN/arn:aws:s3::::/}?prefix=${{ github.run_id }}" >> $GITHUB_OUTPUT
          echo "version_file_url=$root_url/VERSION.json" >> $GITHUB_OUTPUT
          echo "system_url=$root_url/ot3-system.zip" >> $GITHUB_OUTPUT
          echo "fullimage_url=$root_url/ot3-fullimage.tar" >> $GITHUB_OUTPUT
      - name: Post results
        if: ${{ matrix.build_env == 'stage-prod' }}
        uses: slackapi/slack-github-action@v1.14.0
        with:
          payload: "{\"s3-url\":\"${{ steps.upload-results.outputs.console_url }}/\",\"type\":\"branch\", \"reflike\":\"${{ github.ref }}\", \"full-image\":\"${{ steps.upload-results.outputs.fullimage_url }}\", \"system-update\":\"${{ steps.upload-results.outputs.system_url }}\", \"version-file\":\"${{ steps.upload-results.outputs.version_file_url }}\"}"
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
      - name: Remove build data
        if: always()
        run: |
          rm -rf ./*
