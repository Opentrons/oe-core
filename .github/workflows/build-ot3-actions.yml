name: 'Build OT3 image on github workflows'

on:
  push:
    branches:
      - '*'
    tags-ignore:
      - '*'
  workflow_dispatch:

jobs:
  run-build:
    name: 'Building images'
    timeout-minutes: 480
    strategy:
      matrix:
        build-env: ['dev']
    runs-on: ['self-hosted', ${{matrix.build-env}}]
    steps:
      - name: Fetch sources
        uses: 'actions/checkout@v3'
        with:
          submodules: true
          fetch-depth: 0
      - name: Configure AWS Credentials
        run: |
          aws configure set aws_access_key_id ${{ secrets.ROBOT_STACK_AWS_ACCESS_KEY_ID }} --profile identity
          aws configure set aws_secret_access_key ${{ secrets.ROBOT_STACK_AWS_SECRET_ACCESS_KEY }} --profile identity
          aws configure set region us-east-2 --profile identity
          aws configure set output json --profile identity
        shell: bash
      - name: Add dev infra config
        if: matrix.build-env == 'dev'
        run: |
          aws configure set region us-east-2 --profile deploy
          aws configure set role_arn arn:aws:iam::699250785121:role/administrator --profile deploy
          aws configure set source_profile identity --profile deploy
      - name: add staging or prod infra config
        if: matrix.build_env != 'dev'
        run: |
          aws configure set region us-east-2 --profile deploy
          aws configure set role_arn arn:aws:iam::879285218407:role/administrator --profile deploy
          aws configure set source_profile identity --profile deploy
        shell: bash
      - name: Build container
        run: |
          tmp_dir=$(mktemp -d -t ci-XXXXXXX)
          cp start.sh $tmp_dir/
          docker build -f ./Dockerfile --tag "ot3-image:latest" $tmp_dir
      - name: Apply CI config overrides
        run: |
          echo "" >> ./build/conf/local.conf
          echo 'DL_DIR = "/volumes/cache/downloads"' >> ./build/conf/local.conf
          echo 'SSTATE_DIR = "/volumes/cache/sstate"' >> ./build/conf/local.conf
      - name: Pull S3 cache
        shell: bash
        run: |
          synccommand="aws --profile=deploy s3 sync s3://${S3_CACHE_ARN/arn:aws:s3:::/} ${LOCAL_CACHE:-./cache}"
          echo $synccommand
          $synccommand
      - name: Download sources
        run: |
          docker run --rm --mount type=bind,src=$(pwd),dst=/volumes/oe-core,consistency=delegated --mount type=bind,src=${LOCAL_CACHE:-./cache},dst=/volumes/cache,consistency=delegated ot3-image:latest opentrons-ot3-image --runall=fetch
      - name: Build image
        run: |
          docker run --rm --mount type=bind,src=$(pwd),dst=/volumes/oe-core,consistency=delegated --mount type=bind,src=${LOCAL_CACHE:-./cache},dst=/volumes/cache,consistency=delegated ot3-image:latest
      - name: Prune images
        if: always()
        run: docker image prune -af
      - name: Remove poisoned cache
        if: failure()
        run: |
          rm -rf ${LOCAL_CACHE:-./cache}/*
      - name: Push S3 cache
        shell: bash
        run: |
          aws --profile=deploy s3 sync ${LOCAL_CACHE:-./cache} s3://${S3_CACHE_ARN/arn:aws:s3:::/}
      - name: Gather results
        run: |
          mkdir -p build/deploy/opentrons
          find ./build/deploy/images -name "*opentrons-ot3-image-Tezi*" -exec cp {} build/deploy/opentrons/ot3-fullimage.tar \;
          find ./build/deploy/images -name "ot3-system.zip" -exec cp {} build/deploy/opentrons \;
          find ./build/deploy/images -name "VERSION.json" -exec cp {} build/deploy/opentrons \;
          tar czf ./build/deploy/opentrons/buildstats.tar.gz ./build/tmp/buildstats
      - name: Upload results to S3
        shell: bash
        run: |
          cd build/deploy/
          aws --profile=deploy s3 cp --acl=public-read --recursive opentrons s3://${S3_ARTIFACT_ARN/arn:aws:s3:::/}/ot3-oe/${{ github.run_id }}
